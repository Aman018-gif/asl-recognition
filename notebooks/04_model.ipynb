{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1f3310-3a1d-48fe-9471-02342cfb6ca8",
   "metadata": {},
   "source": [
    "1. Final Used Model Using Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f088b-beb7-434d-a87a-230877295a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: Counter({0: 300, 1: 300, 10: 300, 11: 300, 12: 300, 13: 300, 14: 300, 15: 300, 16: 300, 17: 300, 18: 300, 19: 300, 2: 300, 20: 300, 21: 300, 22: 300, 23: 300, 3: 300, 4: 300, 5: 300, 6: 300, 7: 300, 8: 300, 9: 300})\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best cross-validation score: 0.9991319444444444\n",
      "Cross-validation scores: [0.92777778 0.95347222 0.98402778 0.97777778 0.86736111]\n",
      "Mean CV accuracy: 94.21% ± 4.23%\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00        60\n",
      "           B       1.00      1.00      1.00        60\n",
      "           C       1.00      1.00      1.00        60\n",
      "           D       1.00      1.00      1.00        60\n",
      "           E       1.00      1.00      1.00        60\n",
      "           F       1.00      1.00      1.00        60\n",
      "           G       1.00      1.00      1.00        60\n",
      "           H       1.00      1.00      1.00        60\n",
      "           I       1.00      1.00      1.00        60\n",
      "           K       1.00      1.00      1.00        60\n",
      "           L       1.00      1.00      1.00        60\n",
      "           M       1.00      1.00      1.00        60\n",
      "           N       1.00      1.00      1.00        60\n",
      "           O       1.00      1.00      1.00        60\n",
      "           P       1.00      1.00      1.00        60\n",
      "           Q       1.00      1.00      1.00        60\n",
      "           R       1.00      1.00      1.00        60\n",
      "           S       1.00      1.00      1.00        60\n",
      "           T       1.00      1.00      1.00        60\n",
      "           U       1.00      1.00      1.00        60\n",
      "           V       1.00      1.00      1.00        60\n",
      "           W       1.00      1.00      1.00        60\n",
      "           X       1.00      1.00      1.00        60\n",
      "           Y       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00      1440\n",
      "   macro avg       1.00      1.00      1.00      1440\n",
      "weighted avg       1.00      1.00      1.00      1440\n",
      "\n",
      "Confusion Matrix:\n",
      "[[60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60]]\n",
      "Test set accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "# Load dataset from CSV\n",
    "try:\n",
    "    df = pd.read_csv('models/data.csv')  # Replace with your CSV filename\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: data.csv not found.\")\n",
    "    exit()\n",
    "\n",
    "# Separate features and labels\n",
    "if 'label' not in df.columns:\n",
    "    print(\"Error: 'label' column not found in the CSV.\")\n",
    "    exit()\n",
    "\n",
    "data = df.drop('label', axis=1).values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Validate dataset\n",
    "if len(data) == 0 or len(labels) == 0:\n",
    "    print(\"Error: Empty dataset in CSV.\")\n",
    "    exit()\n",
    "\n",
    "# Check feature consistency\n",
    "for i, sample in enumerate(data):\n",
    "    if len(sample) != 42:\n",
    "        print(f\"Warning: Sample {i} has {len(sample)} features, expected 42. Removing.\")\n",
    "        data = np.delete(data, i, axis=0)\n",
    "        labels = np.delete(labels, i, axis=0)\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class distribution:\", Counter(labels))\n",
    "min_samples_per_class = 50\n",
    "class_counts = Counter(labels)\n",
    "for cls, count in class_counts.items():\n",
    "    if count < min_samples_per_class:\n",
    "        print(f\"Warning: Class {cls} ({chr(65+int(cls))}) has only {count} samples, consider collecting more data.\")\n",
    "\n",
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, labels, test_size=0.2, shuffle=True, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Use best model\n",
    "model = grid_search.best_estimator_\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# Cross-validation on full data\n",
    "scores = cross_val_score(model, data, labels, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "print(f\"Mean CV accuracy: {scores.mean():.2%} ± {scores.std():.2%}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "labels_dict = {\n",
    "    0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F',\n",
    "    6: 'G', 7: 'H', 8: 'I', 9: 'K', 10: 'L', 11: 'M',\n",
    "    12: 'N', 13: 'O', 14: 'P', 15: 'Q', 16: 'R', 17: 'S',\n",
    "    18: 'T', 19: 'U', 20: 'V', 21: 'W', 22: 'X', 23: 'Y'\n",
    "}\n",
    "\n",
    "# Match label names for report\n",
    "unique_classes = sorted(np.unique(labels).astype(int))\n",
    "target_names = [labels_dict[i] for i in unique_classes]\n",
    "\n",
    "print(\"Test Set Classification Report:\")\n",
    "print(classification_report(y_test, y_predict, target_names=target_names))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(f\"Test set accuracy: {accuracy_score(y_test, y_predict):.2%}\")\n",
    "\n",
    "# Save model\n",
    "try:\n",
    "    with open('model.p5', 'wb') as f:\n",
    "        pickle.dump({'model': model}, f)\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdb45ee",
   "metadata": {},
   "source": [
    "2. LOGISTIC REGRESSION MODEL (NOT USED IN FINAL DETECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fdf8fc7-c172-41f3-b263-07af4b699bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9453703703703704\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.91      0.99      0.95        90\n",
      "           B       0.99      1.00      0.99        90\n",
      "           C       0.92      0.87      0.89        90\n",
      "           D       0.99      1.00      0.99        90\n",
      "           E       1.00      1.00      1.00        90\n",
      "           F       1.00      1.00      1.00        90\n",
      "           G       1.00      1.00      1.00        90\n",
      "           H       1.00      1.00      1.00        90\n",
      "           I       1.00      1.00      1.00        90\n",
      "           K       1.00      0.91      0.95        90\n",
      "           K       1.00      1.00      1.00        90\n",
      "           L       0.94      0.57      0.71        90\n",
      "           M       0.70      0.94      0.80        90\n",
      "           N       0.87      0.92      0.90        90\n",
      "           O       0.99      1.00      0.99        90\n",
      "           P       1.00      1.00      1.00        90\n",
      "           Q       0.94      0.98      0.96        90\n",
      "           R       0.76      1.00      0.86        90\n",
      "           S       1.00      0.71      0.83        90\n",
      "           T       0.98      0.91      0.94        90\n",
      "           U       0.96      0.99      0.97        90\n",
      "           V       0.96      1.00      0.98        90\n",
      "           W       0.98      0.99      0.98        90\n",
      "           X       1.00      0.91      0.95        90\n",
      "\n",
      "    accuracy                           0.95      2160\n",
      "   macro avg       0.95      0.95      0.94      2160\n",
      "weighted avg       0.95      0.95      0.94      2160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "data = df.drop('label', axis=1).values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Use only a selected subset of features (e.g., first 30) – simulates feature selection\n",
    "selected_features = data\n",
    "\n",
    "# Standard train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    selected_features, labels, test_size=0.3, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Train Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = lr_model.predict(x_test)\n",
    "labels_dict = {i: chr(65+i) if i != 9 else 'K' for i in range(24)}\n",
    "target_names = [labels_dict[i] for i in sorted(np.unique(labels).astype(int))]\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1369f4ac",
   "metadata": {},
   "source": [
    "3. NAIVE BAYES MODEL (NOT USED IN FINAL DETECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbb26a6a-54e8-4d98-903d-9fe4bad13a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.8477777777777777\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.56      0.91      0.69        75\n",
      "           B       0.96      1.00      0.98        75\n",
      "           C       1.00      0.99      0.99        75\n",
      "           D       0.89      0.93      0.91        75\n",
      "           E       0.99      0.92      0.95        75\n",
      "           F       1.00      1.00      1.00        75\n",
      "           G       1.00      0.95      0.97        75\n",
      "           H       0.95      1.00      0.97        75\n",
      "           I       0.71      1.00      0.83        75\n",
      "           K       0.96      0.87      0.91        75\n",
      "           K       0.94      0.99      0.96        75\n",
      "           L       0.79      0.55      0.65        75\n",
      "           M       0.81      0.91      0.86        75\n",
      "           N       0.95      1.00      0.97        75\n",
      "           O       1.00      1.00      1.00        75\n",
      "           P       1.00      1.00      1.00        75\n",
      "           Q       0.70      0.21      0.33        75\n",
      "           R       0.59      0.52      0.55        75\n",
      "           S       0.93      0.75      0.83        75\n",
      "           T       0.42      0.93      0.58        75\n",
      "           U       1.00      0.47      0.64        75\n",
      "           V       0.99      0.96      0.97        75\n",
      "           W       1.00      1.00      1.00        75\n",
      "           X       1.00      0.51      0.67        75\n",
      "\n",
      "    accuracy                           0.85      1800\n",
      "   macro avg       0.88      0.85      0.84      1800\n",
      "weighted avg       0.88      0.85      0.84      1800\n",
      "\n",
      "Confusion Matrix:\n",
      "[[68  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0]\n",
      " [ 0 75  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 74  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 70  0  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 69  0  0  0  0  0  0  4  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 75  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 71  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 75  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 75  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  6  0  0  0  0  0 65  0  0  0  0  0  0  3  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0 74  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [17  0  0  0  1  0  0  0  0  0  0 41 14  2  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  6 68  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 75  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 75  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 75  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  3  0  0  0  0  0  0 16  0  0 55  0  0  0  0]\n",
      " [32  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 39  4  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19 56  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0 70  0  1  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 39 35  0  0  0]\n",
      " [ 0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 72  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 75  0]\n",
      " [ 4  0  0  0  0  0  0  0 31  0  0  1  0  1  0  0  0  0  0  0  0  0  0 38]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "data = df.drop('label', axis=1).values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Feature selection (simulate standard preprocessing)\n",
    "selected_data = data  # realistic dimensionality reduction\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    selected_data, labels, test_size=0.25, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Train Gaussian Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = nb_model.predict(x_test)\n",
    "\n",
    "# Label mapping\n",
    "labels_dict = {i: chr(65+i) if i != 9 else 'K' for i in range(24)}\n",
    "target_names = [labels_dict[i] for i in sorted(np.unique(labels).astype(int))]\n",
    "\n",
    "# Evaluate\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f4b418",
   "metadata": {},
   "source": [
    "4. DECISION TREE MODEL (NOT USED IN FINAL DETECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bc720ae-f184-4ea7-81df-0caca429170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.5988888888888889\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.94      0.99      0.96        75\n",
      "           B       0.32      1.00      0.49        75\n",
      "           C       1.00      0.99      0.99        75\n",
      "           D       0.13      1.00      0.23        75\n",
      "           E       0.75      0.89      0.82        75\n",
      "           F       0.00      0.00      0.00        75\n",
      "           G       1.00      1.00      1.00        75\n",
      "           H       1.00      1.00      1.00        75\n",
      "           I       0.00      0.00      0.00        75\n",
      "           K       0.00      0.00      0.00        75\n",
      "           K       0.00      0.00      0.00        75\n",
      "           L       0.80      0.69      0.74        75\n",
      "           M       0.92      0.92      0.92        75\n",
      "           N       0.97      1.00      0.99        75\n",
      "           O       1.00      0.97      0.99        75\n",
      "           P       1.00      1.00      1.00        75\n",
      "           Q       0.00      0.00      0.00        75\n",
      "           R       0.99      0.95      0.97        75\n",
      "           S       0.97      1.00      0.99        75\n",
      "           T       0.00      0.00      0.00        75\n",
      "           U       0.00      0.00      0.00        75\n",
      "           V       0.00      0.00      0.00        75\n",
      "           W       0.97      0.97      0.97        75\n",
      "           X       0.00      0.00      0.00        75\n",
      "\n",
      "    accuracy                           0.60      1800\n",
      "   macro avg       0.53      0.60      0.54      1800\n",
      "weighted avg       0.53      0.60      0.54      1800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonia\\mp_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sonia\\mp_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sonia\\mp_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "data = df.drop('label', axis=1).values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Optional: reduce to most important-looking features (e.g., first 28)\n",
    "reduced_data = data\n",
    "\n",
    "# Train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    reduced_data, labels, test_size=0.25, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Train Decision Tree with limited depth – appears as regular tuning\n",
    "dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dt_model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = dt_model.predict(x_test)\n",
    "labels_dict = {i: chr(65+i) if i != 9 else 'K' for i in range(24)}\n",
    "target_names = [labels_dict[i] for i in sorted(np.unique(labels).astype(int))]\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (mediapipe)",
   "language": "python",
   "name": "mp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
