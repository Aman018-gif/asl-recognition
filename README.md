# Real-Time American Sign Language Recognition using MediaPipe and Random Forest on Raspberry Pi

This project implements a real-time American Sign Language (ASL) recognition system using **MediaPipe** for hand landmark detection and **Random Forest** for classification. Designed for hardware deployment, the system runs efficiently on a **Raspberry Pi**, enabling low-cost, portable assistive technology.

---

## ğŸ“Œ Abstract

Hand sign recognition plays a critical role in gesture-based interfaces and accessibility tools. This project presents a lightweight and accurate ASL recognition pipeline that processes static hand gestures using **21 hand landmarks** extracted via MediaPipe. Each landmark's 2D coordinates (x, y) are normalized, forming a 42-dimensional feature vector.

We evaluated five machine learning models:
- Random Forest (ğŸ† best performance â€“ 94.21%)
- Logistic Regression (94.5%)
- Naive Bayes (84.78%)
- Decision Tree (59.89%)
- Angle-based approach (discarded due to poor accuracy)

The final model runs in real time on a **Raspberry Pi**, enabling sign language recognition in portable, low-power scenarios.

---

## ğŸ§  Methodology

### 1. Dataset Collection
- Custom dataset of **9,000+ images**, ~300 per ASL alphabet class.
- Collected using webcam + OpenCV + MediaPipe in various lighting/backgrounds.
- Data organized into folders per letter (`data/A/`, `data/B/`, etc.)

### 2. Feature Extraction
- MediaPipe extracts **21 hand landmarks** per frame.
- Each image converted into a 42-feature vector (x, y coordinates).
- Features are **normalized** for position/scale invariance.

### 3. Model Training
- Models trained and evaluated using cross-validation.
- Final Random Forest model saved as `.p5` for deployment.

### 4. Hardware Deployment
- Optimized and tested on **Raspberry Pi** (4B recommended).
- Supports real-time prediction using onboard camera or USB webcam.

---

## ğŸ—‚ï¸ Repository Structure

```
asl-sign-recognition-raspberrypi/
â”‚
â”œâ”€â”€ data/                       # Image dataset (organized by class)
â”‚   â””â”€â”€ A/, B/, ..., Z/
â”‚
â”œâ”€â”€ models/                    # Saved CSV features & trained model
â”‚   â”œâ”€â”€ data.csv
â”‚   â””â”€â”€ model.p5
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter Notebooks for each stage
â”‚   â”œâ”€â”€ 01_collect_img.ipynb       # Image collection
â”‚   â”œâ”€â”€ 02_create_ds.ipynb         # Feature extraction & dataset creation
â”‚   â”œâ”€â”€ 03_detection.ipynb         # Live hand detection
â”‚   â””â”€â”€ 04_model.ipynb             # Model training & evaluation
â”‚
â””â”€â”€ README.md
```

---

## ğŸš€ Setup Instructions

### Prerequisites
- Python 3.7+
- Raspberry Pi (tested on Pi 4)
- Required libraries:
  ```bash
  pip install mediapipe opencv-python pandas scikit-learn
  ```

### Run the System
1. Collect images: Run `01_collect_img.ipynb`
2. Build dataset: Run `02_create_ds.ipynb`
3. Train model: Run `04_model.ipynb`
4. Deploy on Pi: Follow `raspberry_pi/deployment_guide.md`

---

## ğŸ”¬ Results

| Model               | Accuracy    |
|--------------------|-------------|
| **Random Forest**  | 94.21%      |
| Logistic Regression| 94.5%       |
| Naive Bayes        | 84.78%      |
| Decision Tree      | 59.89%      |

---

## ğŸ§© Applications

- Assistive technology for Deaf or hard-of-hearing users
- Smart interfaces for gesture-based control
- Real-time recognition on embedded devices

---

## ğŸ“š Keywords

American Sign Language, MediaPipe, Raspberry Pi, Random Forest, Gesture Recognition, Human-Computer Interaction, Real-Time ASL

---

ğŸ“œ License
This project is licensed under the MIT License.
You are free to use, modify, and distribute this software with proper attribution.

ğŸ™Œ Acknowledgements
This project was developed as part of an internship at The LNM Institute of Information Technology (LNMIIT), Jaipur.

Special thanks to:

Dr. Sandeep Saini
Dean of Academic Affairs, LNMIIT
For his constant guidance and support throughout the project.

Team Members:

Aman Kaushal

Prakhar Agrawal

Manan Rathi

Lov Chaudary

Libraries and Tools:

MediaPipe by Google for hand landmark detection

OpenCV for image processing and visualization

scikit-learn for model training (Random Forest)

Raspberry Pi for real-time deployment and testing
